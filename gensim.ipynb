{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script generates deep learning training data\n",
    "# Author: Nikita Mishra\n",
    "# run: python Deep_learning_training_data.py\n",
    "\n",
    "# TODO: remove repeated solutions and change start and end position accordingly\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import api_client\n",
    "from api_client import *\n",
    "import random\n",
    "from gensim import models\n",
    "\n",
    "\n",
    "#api_client = SourceFileLoader(\"module.name\", \"../api_client.py\").load_module()\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "SOLUTIONS_FILE = ''.join([DATA_DIR, 'solutions_org'])\n",
    "QUERIES_FILE   = ''.join([DATA_DIR, 'queries_org'])\n",
    "CAUCUSES_FILE  = ''.join([DATA_DIR, 'caucuses_org'])\n",
    "\n",
    "MAX_OUTPUT = 1000000\n",
    "\n",
    "MAX_LENGTH = 500\n",
    "orgs_api = ApiClient('http://localhost:3002', '/v1/orgs')\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return\n",
    "\n",
    "def read(filename):\n",
    "    print('Loading from file ', filename, '...')\n",
    "    with open(filename) as data_file:\n",
    "        return data_file.read().splitlines()\n",
    "    \n",
    "def read_padded(filename, MAX_LENGTH):\n",
    "    print('Loading from file ', filename, '... and adding padding.')     \n",
    "    return [pad(item, MAX_LENGTH) for item in read(filename) ]\n",
    "\n",
    "def pad(sentence,maxlength):\n",
    "    LEN = len(sentence.split(' '))\n",
    "    if LEN>=maxlength:\n",
    "        return sentence[:maxlength]\n",
    "    else:\n",
    "        return ' '.join([sentence]+['BUFFER_PAD']*(maxlength-LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file  /Users/nikita/nmt_data/Upwork/train/sources.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/train/targets.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/train/vocab.sources.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/train/vocab.targets.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/caucus_positive/sources.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/caucus_positive/targets.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/caucus_negative/sources.tok ...\n",
      "Loading from file  /Users/nikita/nmt_data/Upwork/caucus_negative/targets.tok ...\n"
     ]
    }
   ],
   "source": [
    "queries = read('/Users/nikita/nmt_data/Upwork/train/sources.tok')\n",
    "solutions = read('/Users/nikita/nmt_data/Upwork/train/targets.tok')\n",
    "vocab_queries = read('/Users/nikita/nmt_data/Upwork/train/vocab.sources.tok')\n",
    "vocab_solutions = read('/Users/nikita/nmt_data/Upwork/train/vocab.targets.tok')\n",
    "vocab_queries_filtered = [row.split('\\t')[0] for row in vocab_queries]\n",
    "vocab_solutions_filtered = [row.split('\\t')[0] for row in vocab_solutions]\n",
    "\n",
    "# read caucus positive negative\n",
    "\n",
    "queries_caucus_positive = read('/Users/nikita/nmt_data/Upwork/caucus_positive/sources.tok')\n",
    "solutions_caucus_positive = read('/Users/nikita/nmt_data/Upwork/caucus_positive/targets.tok')\n",
    "queries_caucus_negative = read('/Users/nikita/nmt_data/Upwork/caucus_negative/sources.tok')\n",
    "solutions_caucus_negative = read('/Users/nikita/nmt_data/Upwork/caucus_negative/targets.tok')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d7f7aff9b063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msolution_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "query_embedding = Word2Vec(queries, size=1000, window=5, min_count=5, workers=4)\n",
    "solution_embedding = Word2Vec(solutions, size=1000, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-06a0aaead65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_embedding\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "query_embedding =models.word2vec(queries, size=1000, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
